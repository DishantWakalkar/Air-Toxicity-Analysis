{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "from numpy import concatenate\n",
        "from matplotlib import pyplot\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
        "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "# from evaluation import smape\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import ipdb\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PM2.5</th>\n",
              "      <th>PM10</th>\n",
              "      <th>NO</th>\n",
              "      <th>NO2</th>\n",
              "      <th>SO2</th>\n",
              "      <th>CO</th>\n",
              "      <th>Ozone</th>\n",
              "      <th>RH</th>\n",
              "      <th>WS</th>\n",
              "      <th>WD</th>\n",
              "      <th>AT</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17-03-2021 00:00</th>\n",
              "      <td>137.96</td>\n",
              "      <td>272.00</td>\n",
              "      <td>7.97</td>\n",
              "      <td>129.990000</td>\n",
              "      <td>73.270</td>\n",
              "      <td>1.882128</td>\n",
              "      <td>3.470</td>\n",
              "      <td>44.770000</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>236.970000</td>\n",
              "      <td>25.740000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17-03-2021 01:00</th>\n",
              "      <td>111.31</td>\n",
              "      <td>272.00</td>\n",
              "      <td>7.97</td>\n",
              "      <td>94.086667</td>\n",
              "      <td>67.162</td>\n",
              "      <td>1.882128</td>\n",
              "      <td>3.566</td>\n",
              "      <td>50.273333</td>\n",
              "      <td>0.846667</td>\n",
              "      <td>219.323333</td>\n",
              "      <td>25.523333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17-03-2021 02:00</th>\n",
              "      <td>49.00</td>\n",
              "      <td>272.00</td>\n",
              "      <td>7.97</td>\n",
              "      <td>58.183333</td>\n",
              "      <td>61.054</td>\n",
              "      <td>1.496000</td>\n",
              "      <td>3.662</td>\n",
              "      <td>55.776667</td>\n",
              "      <td>0.873333</td>\n",
              "      <td>201.676667</td>\n",
              "      <td>25.306667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17-03-2021 03:00</th>\n",
              "      <td>32.83</td>\n",
              "      <td>272.00</td>\n",
              "      <td>7.97</td>\n",
              "      <td>22.280000</td>\n",
              "      <td>54.946</td>\n",
              "      <td>1.084000</td>\n",
              "      <td>3.758</td>\n",
              "      <td>61.280000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>184.030000</td>\n",
              "      <td>25.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17-03-2021 04:00</th>\n",
              "      <td>50.19</td>\n",
              "      <td>272.00</td>\n",
              "      <td>17.54</td>\n",
              "      <td>42.045000</td>\n",
              "      <td>48.838</td>\n",
              "      <td>0.672000</td>\n",
              "      <td>3.854</td>\n",
              "      <td>60.695000</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>151.750000</td>\n",
              "      <td>24.715000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18-03-2023 15:00</th>\n",
              "      <td>14.93</td>\n",
              "      <td>217.88</td>\n",
              "      <td>10.18</td>\n",
              "      <td>25.750000</td>\n",
              "      <td>25.550</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>49.060</td>\n",
              "      <td>62.990000</td>\n",
              "      <td>2.590000</td>\n",
              "      <td>231.420000</td>\n",
              "      <td>32.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18-03-2023 16:00</th>\n",
              "      <td>17.07</td>\n",
              "      <td>250.22</td>\n",
              "      <td>12.90</td>\n",
              "      <td>24.920000</td>\n",
              "      <td>25.540</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>44.690</td>\n",
              "      <td>66.230000</td>\n",
              "      <td>2.860000</td>\n",
              "      <td>242.130000</td>\n",
              "      <td>31.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18-03-2023 17:00</th>\n",
              "      <td>12.36</td>\n",
              "      <td>236.92</td>\n",
              "      <td>10.55</td>\n",
              "      <td>22.700000</td>\n",
              "      <td>25.560</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>48.020</td>\n",
              "      <td>70.650000</td>\n",
              "      <td>2.540000</td>\n",
              "      <td>243.530000</td>\n",
              "      <td>31.170000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18-03-2023 18:00</th>\n",
              "      <td>13.25</td>\n",
              "      <td>189.68</td>\n",
              "      <td>10.98</td>\n",
              "      <td>24.550000</td>\n",
              "      <td>25.550</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>43.670</td>\n",
              "      <td>77.600000</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>244.630000</td>\n",
              "      <td>30.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18-03-2023 19:00</th>\n",
              "      <td>13.25</td>\n",
              "      <td>189.68</td>\n",
              "      <td>10.98</td>\n",
              "      <td>24.550000</td>\n",
              "      <td>25.550</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>43.670</td>\n",
              "      <td>77.600000</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>244.630000</td>\n",
              "      <td>30.360000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17564 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   PM2.5    PM10     NO         NO2     SO2        CO   Ozone  \\\n",
              "Date                                                                            \n",
              "17-03-2021 00:00  137.96  272.00   7.97  129.990000  73.270  1.882128   3.470   \n",
              "17-03-2021 01:00  111.31  272.00   7.97   94.086667  67.162  1.882128   3.566   \n",
              "17-03-2021 02:00   49.00  272.00   7.97   58.183333  61.054  1.496000   3.662   \n",
              "17-03-2021 03:00   32.83  272.00   7.97   22.280000  54.946  1.084000   3.758   \n",
              "17-03-2021 04:00   50.19  272.00  17.54   42.045000  48.838  0.672000   3.854   \n",
              "...                  ...     ...    ...         ...     ...       ...     ...   \n",
              "18-03-2023 15:00   14.93  217.88  10.18   25.750000  25.550  0.330000  49.060   \n",
              "18-03-2023 16:00   17.07  250.22  12.90   24.920000  25.540  0.260000  44.690   \n",
              "18-03-2023 17:00   12.36  236.92  10.55   22.700000  25.560  0.230000  48.020   \n",
              "18-03-2023 18:00   13.25  189.68  10.98   24.550000  25.550  0.250000  43.670   \n",
              "18-03-2023 19:00   13.25  189.68  10.98   24.550000  25.550  0.250000  43.670   \n",
              "\n",
              "                         RH        WS          WD         AT  \n",
              "Date                                                          \n",
              "17-03-2021 00:00  44.770000  0.820000  236.970000  25.740000  \n",
              "17-03-2021 01:00  50.273333  0.846667  219.323333  25.523333  \n",
              "17-03-2021 02:00  55.776667  0.873333  201.676667  25.306667  \n",
              "17-03-2021 03:00  61.280000  0.900000  184.030000  25.090000  \n",
              "17-03-2021 04:00  60.695000  0.815000  151.750000  24.715000  \n",
              "...                     ...       ...         ...        ...  \n",
              "18-03-2023 15:00  62.990000  2.590000  231.420000  32.500000  \n",
              "18-03-2023 16:00  66.230000  2.860000  242.130000  31.920000  \n",
              "18-03-2023 17:00  70.650000  2.540000  243.530000  31.170000  \n",
              "18-03-2023 18:00  77.600000  2.050000  244.630000  30.360000  \n",
              "18-03-2023 19:00  77.600000  2.050000  244.630000  30.360000  \n",
              "\n",
              "[17564 rows x 11 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import seaborn as sns; sns.set()\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.dates import DateFormatter\n",
        "import os\n",
        "\n",
        "# read files from directory\n",
        "aq_file_list = []\n",
        "airQ_data_dict = {}\n",
        "\n",
        "# read the file names into list\n",
        "# for aq_file in os.listdir(imputed_data_path):\n",
        "#     if '.csv' in aq_file:\n",
        "#         aq_file_list.append(aq_file)\n",
        "#         airQ_df = pd.read_csv(imputed_data_path+aq_file, header=0, index_col=0)\n",
        "#         airQ_df.time = airQ_df.time.apply(lambda x: pd.Timestamp(x))\n",
        "#         airQ_data_dict[aq_file.replace(\"_imputed.csv\", '')] = airQ_df\n",
        " \n",
        "aq_kurla = pd.read_csv(\"kurla_cleaned.csv\", header=0, index_col=0)\n",
        "# aq_kurla = aq_kurla.time.apply(lambda x: pd.Timestamp(x))\n",
        "aq_kurla.set_index(\"Date\", inplace = True)\n",
        "aq_kurla"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Important Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert series to supervised learning\n",
        "def series_to_supervised(data_df, n_in=1, dropnan=True):\n",
        "\tdata = data_df.values\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, 1):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\tagg.index = data_df.index\n",
        "    \n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna()\n",
        "        \n",
        "\treturn agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# return the dictionary dataframes according to the air quality type for further training & testing\n",
        "# drop the NaN in the separated air types table\n",
        "import ipdb\n",
        "\n",
        "def airQualTypesDataDict(data_df):\n",
        "    # dictionary for storing dataframes\n",
        "    data_dict = {}\n",
        "    \n",
        "    # air quality types list\n",
        "    air_types = ['PM2.5', 'PM10', 'NO2', 'CO', 'O3', 'SO2']\n",
        "    \n",
        "    # features columns containing 'time' label\n",
        "    feature_cols = list(set(data_df.columns) - set(air_types))\n",
        "    \n",
        "    for air in air_types:\n",
        "        # get all the columns\n",
        "        data_cols = feature_cols.copy()\n",
        "        data_cols.append(air)\n",
        "        \n",
        "        # get the dataframe with the specific air type\n",
        "        air_data_df = data_df[data_cols]\n",
        "        \n",
        "        # choose the 'time' as the index\n",
        "        air_data_df.time = air_data_df.time.apply(lambda x: pd.Timestamp(x))\n",
        "        air_data_df = air_data_df.set_index('time')\n",
        "        data_dict[air] = air_data_df\n",
        "        \n",
        "    \n",
        "    return data_dict\n",
        "    \n",
        "    \n",
        "# drop the NaN in the concated air types table\n",
        "def getTrainTestDataDropna(data_df):\n",
        "    # dropna\n",
        "    print ('Total rows before dropna: {}'.format(len(data_df)))\n",
        "    data_df = data_df.dropna()\n",
        "    data_df = data_df.set_index('time')\n",
        "    print ('Total rows after dropna: {}'.format(len(data_df)))\n",
        "\n",
        "    # labels columns\n",
        "    label_cols = ['PM2.5', 'PM10', 'NO2', 'CO', 'O3', 'SO2']\n",
        "    feature_cols = list(set(data_df.columns) - set(label_cols))\n",
        "    \n",
        "    # validation set\n",
        "    val_df = data_df[-48:]\n",
        "    X_val = val_df[feature_cols]\n",
        "    y_val = val_df[label_cols]\n",
        "\n",
        "    # train set\n",
        "    train_df = data_df[:-48]\n",
        "    X_train = train_df[feature_cols]\n",
        "    y_train = train_df[label_cols]\n",
        "    \n",
        "    return X_train, X_val, y_train, y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# return training & validation data\n",
        "def splitTrainValData(data_df, label, n_in, is_predict):\n",
        "    # pred_size\n",
        "    pred_size = 48\n",
        "    \n",
        "    # reframed dataset\n",
        "    data_df = data_df.astype(float)\n",
        "    \n",
        "    # extract the label column firstly\n",
        "    features_df = data_df.drop(columns=[label])\n",
        "    label_col = data_df[[label]]\n",
        "    \n",
        "    reframed = series_to_supervised(features_df, n_in)\n",
        "    # concat the label column\n",
        "    reframed = reframed.merge(label_col, on='time', how='left')\n",
        "    \n",
        "    # drop the NaN the last 48 hours before\n",
        "    reframed_test = reframed[-pred_size:]\n",
        "    reframed_train = reframed[:-pred_size]\n",
        "    reframed_train = reframed_train.dropna()\n",
        "    \n",
        "    reframed_all = pd.DataFrame()\n",
        "    if is_predict:\n",
        "        # reframed data including the test set for final prediction\n",
        "        reframed_all = pd.concat([reframed_train, reframed_test], ignore_index=False)\n",
        "    else:\n",
        "        # reframed data including the validation dataset\n",
        "        reframed_all = reframed_train\n",
        "    \n",
        "    # split into train and test sets\n",
        "    # index\n",
        "    train_index = reframed_all.index[:-pred_size]\n",
        "    test_index = reframed_all.index[-pred_size:]\n",
        "    \n",
        "    values = reframed_all.values\n",
        "    # scaled features\n",
        "    features_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_features = features_scaler.fit_transform(values[:,:-1])\n",
        "    \n",
        "    # scaled labels\n",
        "    labels_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_label = labels_scaler.fit_transform(values[:,-1].reshape(-1,1))\n",
        "    values = np.column_stack((scaled_features, scaled_label))\n",
        "\n",
        "    # split the train & test\n",
        "    train = values[:-pred_size, :]\n",
        "    test = values[-pred_size:, :]\n",
        "    \n",
        "    # split into input and outputs\n",
        "    # features take all values except the var1\n",
        "    train_X, train_y = train[:, :-1], train[:, -1]\n",
        "    test_X, test_y = test[:, :-1], test[:, -1]\n",
        "    \n",
        "    return train_X, test_X, train_y, test_y, train_index, test_index, labels_scaler\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "# from evaluate import smape\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "def smape(actual, predicted):\n",
        "    dividend= np.abs(np.array(actual) - np.array(predicted))\n",
        "    denominator = np.array(actual) + np.array(predicted)\n",
        "    \n",
        "    return 2 * np.mean(np.divide(dividend, denominator, out=np.zeros_like(dividend), where=denominator!=0, casting='unsafe'))\n",
        "\n",
        "\n",
        "# from evaluation import smape\n",
        "\n",
        "def evaluation(real, pred):\n",
        "    mse_score = mean_squared_error(real, pred)\n",
        "    rmse_score = math.sqrt(mse_score)\n",
        "    smape_score = smape(real, pred)\n",
        "    \n",
        "    print (\"MSE: {}\".format(mse_score))\n",
        "    print (\"RMSE: {}\".format(rmse_score))\n",
        "    print (\"SMAPE: {}\".format(smape_score))\n",
        "    print('R^2 score: {:2f}'.format(r2_score(real, pred)))\n",
        "    return rmse_score, smape_score\n",
        "    \n",
        "A = np.array([2,3,4,5,6,7,8,9])\n",
        "F = np.array([1,3,5,4,6,7,10,7])\n",
        "print(smape(A, F))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "XG-Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipdb\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "airQ_types = ['PM2.5', 'PM10', 'O3', 'CO', 'SO2', 'NO2']\n",
        "\n",
        "def xgb(airQ_df, n_estimators, n_in, is_predict):\n",
        "    rmse_dict = {}\n",
        "    smape_dict = {}\n",
        "    for air_type in airQ_types[:3]:\n",
        "        # final optimal parameters\n",
        "        n_in = 1\n",
        "        n_est = 100\n",
        "        \n",
        "        if air_type == 'PM2.5':\n",
        "            n_in = 12\n",
        "            n_est = 1000\n",
        "        elif air_type == 'PM10':\n",
        "            n_in = 1\n",
        "            n_est = 200\n",
        "        elif air_type == 'O3':\n",
        "            n_in = 15\n",
        "            n_est = 100\n",
        "            \n",
        "#         n_estimators = n_est\n",
        "            \n",
        "            \n",
        "        air_type_dict = airQualTypesDataDict(airQ_df)\n",
        "        X_train, X_val, y_train, y_val, train_index, val_index, scaler = \\\n",
        "            splitTrainValData(air_type_dict[air_type], air_type, n_in, is_predict)\n",
        "        \n",
        "        # Model\n",
        "        model_xgb = XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
        "                                 learning_rate=0.05, max_depth=3, \n",
        "                                 min_child_weight=1.7817, n_estimators=n_estimators,\n",
        "                                 reg_alpha=0.4640, reg_lambda=0.8571,\n",
        "                                 subsample=0.5213, silent=1,\n",
        "                                 random_state =7, nthread = -1)\n",
        "\n",
        "        # time count\n",
        "        start = time.time()\n",
        "\n",
        "        # make a prediction\n",
        "        model_xgb.fit(X_train, y_train)\n",
        "        yhat = model_xgb.predict(X_val)\n",
        "\n",
        "        # invert scaling for forecast\n",
        "#         inv_yhat = concatenate((yhat, X_val[:, 1:]), axis=1)\n",
        "        inv_yhat = scaler.inverse_transform(yhat.reshape(-1, 1))\n",
        "        inv_yhat = inv_yhat[:,0]\n",
        "\n",
        "        # invert scaling for actual\n",
        "#         y_val = y_val.reshape((len(y_val), 1))\n",
        "#         inv_y = concatenate((y_val, X_val[:, 1:]), axis=1)\n",
        "        inv_y = scaler.inverse_transform(y_val.reshape(-1, 1))\n",
        "        inv_y = inv_y[:,0]\n",
        "\n",
        "        end = time.time()\n",
        "        print('This took {} seconds.'.format(end - start))\n",
        "\n",
        "        # inversed labels dataframe\n",
        "        y_val_inversed = inv_y\n",
        "        y_val_inversed_df = pd.DataFrame(y_val_inversed, index=val_index, columns=[air_type])\n",
        "\n",
        "        pred_inversed = [x if x > 0 else 0 for x in inv_yhat]\n",
        "        pred_inversed_df = pd.DataFrame(pred_inversed, index=val_index, columns=[air_type])\n",
        "\n",
        "        # Evaluation result\n",
        "        rmse_score, smape_score = evaluation(y_val_inversed, pred_inversed)\n",
        "        rmse_dict[air_type] = rmse_score\n",
        "        smape_dict[air_type] = smape_score\n",
        "\n",
        "        # draw line chart\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        ax.plot(val_index, y_val_inversed_df[[air_type]], color='b', label='True')\n",
        "        ax.plot(val_index, pred_inversed_df[[air_type]], color='orange', label='Prediction')\n",
        "\n",
        "        ax.set_title(air_type, fontweight=\"bold\", size=16)\n",
        "        ax.legend(loc=\"upper right\")\n",
        "        myFmt = DateFormatter(\"%m %d %H\")\n",
        "        ax.xaxis.set_major_formatter(myFmt)\n",
        "\n",
        "        ## Rotate date labels automatically\n",
        "        fig.autofmt_xdate()\n",
        "        plt.show()\n",
        "        \n",
        "    return rmse_dict, smape_dict"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analysis\n",
        "\n",
        "Suitable sequence hours for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================== 1 ===========================\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'aotizhongxin_aq'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m seq_hours:\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m====================== \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m ===========================\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i))\n\u001b[0;32m----> 9\u001b[0m     rmse_dict, smape_dict \u001b[39m=\u001b[39m xgb(airQ_data_dict[\u001b[39m'\u001b[39;49m\u001b[39maotizhongxin_aq\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m1000\u001b[39m, i, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m     \u001b[39m# O3\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     o_3[\u001b[39m'\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(rmse_dict[\u001b[39m'\u001b[39m\u001b[39mO3\u001b[39m\u001b[39m'\u001b[39m])\n",
            "\u001b[0;31mKeyError\u001b[0m: 'aotizhongxin_aq'"
          ]
        }
      ],
      "source": [
        "# make a comparison of the different sequence hours for prediction\n",
        "o_3 = {'rmse': [], 'smape': []}\n",
        "pm25 = {'rmse': [], 'smape': []}\n",
        "pm10 = {'rmse': [], 'smape': []}\n",
        "seq_hours = [1, 3, 6, 9, 12, 15, 18, 21, 24]\n",
        "\n",
        "for i in seq_hours:\n",
        "    print (\"====================== {} ===========================\".format(i))\n",
        "    rmse_dict, smape_dict = xgb(airQ_data_dict['aotizhongxin_aq'], 1000, i, False)\n",
        "    \n",
        "    # O3\n",
        "    o_3['rmse'].append(rmse_dict['O3'])\n",
        "    o_3['smape'].append(smape_dict['O3'])\n",
        "    \n",
        "    # PM2.5\n",
        "    pm25['rmse'].append(rmse_dict['PM2.5'])\n",
        "    pm25['smape'].append(smape_dict['PM2.5'])\n",
        "    \n",
        "    # PM10\n",
        "    pm10['rmse'].append(rmse_dict['PM10'])\n",
        "    pm10['smape'].append(smape_dict['PM10'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
