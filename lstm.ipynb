{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "from numpy import concatenate\n",
        "from matplotlib import pyplot\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
        "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "# from evaluation import smape\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import ipdb\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PM2.5</th>\n",
              "      <th>PM10</th>\n",
              "      <th>NO</th>\n",
              "      <th>NO2</th>\n",
              "      <th>SO2</th>\n",
              "      <th>CO</th>\n",
              "      <th>Ozone</th>\n",
              "      <th>RH</th>\n",
              "      <th>WS</th>\n",
              "      <th>WD</th>\n",
              "      <th>AT</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>137.96</td>\n",
              "      <td>272.00</td>\n",
              "      <td>7.97</td>\n",
              "      <td>129.990000</td>\n",
              "      <td>73.270</td>\n",
              "      <td>1.882128</td>\n",
              "      <td>3.470</td>\n",
              "      <td>44.770000</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>236.970000</td>\n",
              "      <td>25.740000</td>\n",
              "      <td>17-03-2021 00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111.31</td>\n",
              "      <td>272.00</td>\n",
              "      <td>7.97</td>\n",
              "      <td>94.086667</td>\n",
              "      <td>67.162</td>\n",
              "      <td>1.882128</td>\n",
              "      <td>3.566</td>\n",
              "      <td>50.273333</td>\n",
              "      <td>0.846667</td>\n",
              "      <td>219.323333</td>\n",
              "      <td>25.523333</td>\n",
              "      <td>17-03-2021 01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49.00</td>\n",
              "      <td>272.00</td>\n",
              "      <td>7.97</td>\n",
              "      <td>58.183333</td>\n",
              "      <td>61.054</td>\n",
              "      <td>1.496000</td>\n",
              "      <td>3.662</td>\n",
              "      <td>55.776667</td>\n",
              "      <td>0.873333</td>\n",
              "      <td>201.676667</td>\n",
              "      <td>25.306667</td>\n",
              "      <td>17-03-2021 02:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32.83</td>\n",
              "      <td>272.00</td>\n",
              "      <td>7.97</td>\n",
              "      <td>22.280000</td>\n",
              "      <td>54.946</td>\n",
              "      <td>1.084000</td>\n",
              "      <td>3.758</td>\n",
              "      <td>61.280000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>184.030000</td>\n",
              "      <td>25.090000</td>\n",
              "      <td>17-03-2021 03:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50.19</td>\n",
              "      <td>272.00</td>\n",
              "      <td>17.54</td>\n",
              "      <td>42.045000</td>\n",
              "      <td>48.838</td>\n",
              "      <td>0.672000</td>\n",
              "      <td>3.854</td>\n",
              "      <td>60.695000</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>151.750000</td>\n",
              "      <td>24.715000</td>\n",
              "      <td>17-03-2021 04:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17559</th>\n",
              "      <td>14.93</td>\n",
              "      <td>217.88</td>\n",
              "      <td>10.18</td>\n",
              "      <td>25.750000</td>\n",
              "      <td>25.550</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>49.060</td>\n",
              "      <td>62.990000</td>\n",
              "      <td>2.590000</td>\n",
              "      <td>231.420000</td>\n",
              "      <td>32.500000</td>\n",
              "      <td>18-03-2023 15:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17560</th>\n",
              "      <td>17.07</td>\n",
              "      <td>250.22</td>\n",
              "      <td>12.90</td>\n",
              "      <td>24.920000</td>\n",
              "      <td>25.540</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>44.690</td>\n",
              "      <td>66.230000</td>\n",
              "      <td>2.860000</td>\n",
              "      <td>242.130000</td>\n",
              "      <td>31.920000</td>\n",
              "      <td>18-03-2023 16:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17561</th>\n",
              "      <td>12.36</td>\n",
              "      <td>236.92</td>\n",
              "      <td>10.55</td>\n",
              "      <td>22.700000</td>\n",
              "      <td>25.560</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>48.020</td>\n",
              "      <td>70.650000</td>\n",
              "      <td>2.540000</td>\n",
              "      <td>243.530000</td>\n",
              "      <td>31.170000</td>\n",
              "      <td>18-03-2023 17:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17562</th>\n",
              "      <td>13.25</td>\n",
              "      <td>189.68</td>\n",
              "      <td>10.98</td>\n",
              "      <td>24.550000</td>\n",
              "      <td>25.550</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>43.670</td>\n",
              "      <td>77.600000</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>244.630000</td>\n",
              "      <td>30.360000</td>\n",
              "      <td>18-03-2023 18:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17563</th>\n",
              "      <td>13.25</td>\n",
              "      <td>189.68</td>\n",
              "      <td>10.98</td>\n",
              "      <td>24.550000</td>\n",
              "      <td>25.550</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>43.670</td>\n",
              "      <td>77.600000</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>244.630000</td>\n",
              "      <td>30.360000</td>\n",
              "      <td>18-03-2023 19:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17564 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        PM2.5    PM10     NO         NO2     SO2        CO   Ozone         RH  \\\n",
              "0      137.96  272.00   7.97  129.990000  73.270  1.882128   3.470  44.770000   \n",
              "1      111.31  272.00   7.97   94.086667  67.162  1.882128   3.566  50.273333   \n",
              "2       49.00  272.00   7.97   58.183333  61.054  1.496000   3.662  55.776667   \n",
              "3       32.83  272.00   7.97   22.280000  54.946  1.084000   3.758  61.280000   \n",
              "4       50.19  272.00  17.54   42.045000  48.838  0.672000   3.854  60.695000   \n",
              "...       ...     ...    ...         ...     ...       ...     ...        ...   \n",
              "17559   14.93  217.88  10.18   25.750000  25.550  0.330000  49.060  62.990000   \n",
              "17560   17.07  250.22  12.90   24.920000  25.540  0.260000  44.690  66.230000   \n",
              "17561   12.36  236.92  10.55   22.700000  25.560  0.230000  48.020  70.650000   \n",
              "17562   13.25  189.68  10.98   24.550000  25.550  0.250000  43.670  77.600000   \n",
              "17563   13.25  189.68  10.98   24.550000  25.550  0.250000  43.670  77.600000   \n",
              "\n",
              "             WS          WD         AT              Date  \n",
              "0      0.820000  236.970000  25.740000  17-03-2021 00:00  \n",
              "1      0.846667  219.323333  25.523333  17-03-2021 01:00  \n",
              "2      0.873333  201.676667  25.306667  17-03-2021 02:00  \n",
              "3      0.900000  184.030000  25.090000  17-03-2021 03:00  \n",
              "4      0.815000  151.750000  24.715000  17-03-2021 04:00  \n",
              "...         ...         ...        ...               ...  \n",
              "17559  2.590000  231.420000  32.500000  18-03-2023 15:00  \n",
              "17560  2.860000  242.130000  31.920000  18-03-2023 16:00  \n",
              "17561  2.540000  243.530000  31.170000  18-03-2023 17:00  \n",
              "17562  2.050000  244.630000  30.360000  18-03-2023 18:00  \n",
              "17563  2.050000  244.630000  30.360000  18-03-2023 19:00  \n",
              "\n",
              "[17564 rows x 12 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import seaborn as sns; sns.set()\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.dates import DateFormatter\n",
        "import os\n",
        "\n",
        "# read files from directory\n",
        "aq_file_list = []\n",
        "airQ_data_dict = {}\n",
        "\n",
        "# read the file names into list\n",
        "# for aq_file in os.listdir(imputed_data_path):\n",
        "#     if '.csv' in aq_file:\n",
        "#         aq_file_list.append(aq_file)\n",
        "#         airQ_df = pd.read_csv(imputed_data_path+aq_file, header=0, index_col=0)\n",
        "#         airQ_df.time = airQ_df.time.apply(lambda x: pd.Timestamp(x))\n",
        "#         airQ_data_dict[aq_file.replace(\"_imputed.csv\", '')] = airQ_df\n",
        " \n",
        "aq_kurla = pd.read_csv(\"kurla_cleaned.csv\", header=0, index_col=0)\n",
        "# aq_kurla = aq_kurla.time.apply(lambda x: pd.Timestamp(x))\n",
        "\n",
        "aq_kurla"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Important Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert series to supervised learning\n",
        "def series_to_supervised(data_df, n_in=1, dropnan=True):\n",
        "\tdata = data_df.values\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, 1):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\tagg.index = data_df.index\n",
        "    \n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna()\n",
        "        \n",
        "\treturn agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# return the dictionary dataframes according to the air quality type for further training & testing\n",
        "# drop the NaN in the separated air types table\n",
        "import ipdb\n",
        "\n",
        "def airQualTypesDataDict(data_df):\n",
        "    # dictionary for storing dataframes\n",
        "    data_dict = {}\n",
        "    \n",
        "    # air quality types list\n",
        "    air_types = ['PM2.5', 'PM10', 'NO2', 'CO', 'O3', 'SO2']\n",
        "    \n",
        "    # features columns containing 'time' label\n",
        "    feature_cols = list(set(data_df.columns) - set(air_types))\n",
        "    \n",
        "    for air in air_types:\n",
        "        # get all the columns\n",
        "        data_cols = feature_cols.copy()\n",
        "        data_cols.append(air)\n",
        "        \n",
        "        # get the dataframe with the specific air type\n",
        "        air_data_df = data_df[data_cols]\n",
        "        \n",
        "        # choose the 'time' as the index\n",
        "        air_data_df.time = air_data_df.time.apply(lambda x: pd.Timestamp(x))\n",
        "        air_data_df = air_data_df.set_index('time')\n",
        "        data_dict[air] = air_data_df\n",
        "        \n",
        "    \n",
        "    return data_dict\n",
        "    \n",
        "    \n",
        "# drop the NaN in the concated air types table\n",
        "def getTrainTestDataDropna(data_df):\n",
        "    # dropna\n",
        "    print ('Total rows before dropna: {}'.format(len(data_df)))\n",
        "    data_df = data_df.dropna()\n",
        "    data_df = data_df.set_index('time')\n",
        "    print ('Total rows after dropna: {}'.format(len(data_df)))\n",
        "\n",
        "    # labels columns\n",
        "    label_cols = ['PM2.5', 'PM10', 'NO2', 'CO', 'O3', 'SO2']\n",
        "    feature_cols = list(set(data_df.columns) - set(label_cols))\n",
        "    \n",
        "    # validation set\n",
        "    val_df = data_df[-48:]\n",
        "    X_val = val_df[feature_cols]\n",
        "    y_val = val_df[label_cols]\n",
        "\n",
        "    # train set\n",
        "    train_df = data_df[:-48]\n",
        "    X_train = train_df[feature_cols]\n",
        "    y_train = train_df[label_cols]\n",
        "    \n",
        "    return X_train, X_val, y_train, y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:5516: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'PM2.5':                         NO          WD         AT         RH        WS   PM2.5\n",
              " time                                                                          \n",
              " 2021-03-17 00:00:00   7.97  236.970000  25.740000  44.770000  0.820000  137.96\n",
              " 2021-03-17 01:00:00   7.97  219.323333  25.523333  50.273333  0.846667  111.31\n",
              " 2021-03-17 02:00:00   7.97  201.676667  25.306667  55.776667  0.873333   49.00\n",
              " 2021-03-17 03:00:00   7.97  184.030000  25.090000  61.280000  0.900000   32.83\n",
              " 2021-03-17 04:00:00  17.54  151.750000  24.715000  60.695000  0.815000   50.19\n",
              " ...                    ...         ...        ...        ...       ...     ...\n",
              " 2023-03-18 15:00:00  10.18  231.420000  32.500000  62.990000  2.590000   14.93\n",
              " 2023-03-18 16:00:00  12.90  242.130000  31.920000  66.230000  2.860000   17.07\n",
              " 2023-03-18 17:00:00  10.55  243.530000  31.170000  70.650000  2.540000   12.36\n",
              " 2023-03-18 18:00:00  10.98  244.630000  30.360000  77.600000  2.050000   13.25\n",
              " 2023-03-18 19:00:00  10.98  244.630000  30.360000  77.600000  2.050000   13.25\n",
              " \n",
              " [17564 rows x 6 columns],\n",
              " 'PM10':                         NO          WD         AT         RH        WS    PM10\n",
              " time                                                                          \n",
              " 2021-03-17 00:00:00   7.97  236.970000  25.740000  44.770000  0.820000  272.00\n",
              " 2021-03-17 01:00:00   7.97  219.323333  25.523333  50.273333  0.846667  272.00\n",
              " 2021-03-17 02:00:00   7.97  201.676667  25.306667  55.776667  0.873333  272.00\n",
              " 2021-03-17 03:00:00   7.97  184.030000  25.090000  61.280000  0.900000  272.00\n",
              " 2021-03-17 04:00:00  17.54  151.750000  24.715000  60.695000  0.815000  272.00\n",
              " ...                    ...         ...        ...        ...       ...     ...\n",
              " 2023-03-18 15:00:00  10.18  231.420000  32.500000  62.990000  2.590000  217.88\n",
              " 2023-03-18 16:00:00  12.90  242.130000  31.920000  66.230000  2.860000  250.22\n",
              " 2023-03-18 17:00:00  10.55  243.530000  31.170000  70.650000  2.540000  236.92\n",
              " 2023-03-18 18:00:00  10.98  244.630000  30.360000  77.600000  2.050000  189.68\n",
              " 2023-03-18 19:00:00  10.98  244.630000  30.360000  77.600000  2.050000  189.68\n",
              " \n",
              " [17564 rows x 6 columns],\n",
              " 'NO2':                         NO          WD         AT         RH        WS  \\\n",
              " time                                                                     \n",
              " 2021-03-17 00:00:00   7.97  236.970000  25.740000  44.770000  0.820000   \n",
              " 2021-03-17 01:00:00   7.97  219.323333  25.523333  50.273333  0.846667   \n",
              " 2021-03-17 02:00:00   7.97  201.676667  25.306667  55.776667  0.873333   \n",
              " 2021-03-17 03:00:00   7.97  184.030000  25.090000  61.280000  0.900000   \n",
              " 2021-03-17 04:00:00  17.54  151.750000  24.715000  60.695000  0.815000   \n",
              " ...                    ...         ...        ...        ...       ...   \n",
              " 2023-03-18 15:00:00  10.18  231.420000  32.500000  62.990000  2.590000   \n",
              " 2023-03-18 16:00:00  12.90  242.130000  31.920000  66.230000  2.860000   \n",
              " 2023-03-18 17:00:00  10.55  243.530000  31.170000  70.650000  2.540000   \n",
              " 2023-03-18 18:00:00  10.98  244.630000  30.360000  77.600000  2.050000   \n",
              " 2023-03-18 19:00:00  10.98  244.630000  30.360000  77.600000  2.050000   \n",
              " \n",
              "                             NO2  \n",
              " time                             \n",
              " 2021-03-17 00:00:00  129.990000  \n",
              " 2021-03-17 01:00:00   94.086667  \n",
              " 2021-03-17 02:00:00   58.183333  \n",
              " 2021-03-17 03:00:00   22.280000  \n",
              " 2021-03-17 04:00:00   42.045000  \n",
              " ...                         ...  \n",
              " 2023-03-18 15:00:00   25.750000  \n",
              " 2023-03-18 16:00:00   24.920000  \n",
              " 2023-03-18 17:00:00   22.700000  \n",
              " 2023-03-18 18:00:00   24.550000  \n",
              " 2023-03-18 19:00:00   24.550000  \n",
              " \n",
              " [17564 rows x 6 columns],\n",
              " 'CO':                         NO          WD         AT         RH        WS  \\\n",
              " time                                                                     \n",
              " 2021-03-17 00:00:00   7.97  236.970000  25.740000  44.770000  0.820000   \n",
              " 2021-03-17 01:00:00   7.97  219.323333  25.523333  50.273333  0.846667   \n",
              " 2021-03-17 02:00:00   7.97  201.676667  25.306667  55.776667  0.873333   \n",
              " 2021-03-17 03:00:00   7.97  184.030000  25.090000  61.280000  0.900000   \n",
              " 2021-03-17 04:00:00  17.54  151.750000  24.715000  60.695000  0.815000   \n",
              " ...                    ...         ...        ...        ...       ...   \n",
              " 2023-03-18 15:00:00  10.18  231.420000  32.500000  62.990000  2.590000   \n",
              " 2023-03-18 16:00:00  12.90  242.130000  31.920000  66.230000  2.860000   \n",
              " 2023-03-18 17:00:00  10.55  243.530000  31.170000  70.650000  2.540000   \n",
              " 2023-03-18 18:00:00  10.98  244.630000  30.360000  77.600000  2.050000   \n",
              " 2023-03-18 19:00:00  10.98  244.630000  30.360000  77.600000  2.050000   \n",
              " \n",
              "                            CO  \n",
              " time                           \n",
              " 2021-03-17 00:00:00  1.882128  \n",
              " 2021-03-17 01:00:00  1.882128  \n",
              " 2021-03-17 02:00:00  1.496000  \n",
              " 2021-03-17 03:00:00  1.084000  \n",
              " 2021-03-17 04:00:00  0.672000  \n",
              " ...                       ...  \n",
              " 2023-03-18 15:00:00  0.330000  \n",
              " 2023-03-18 16:00:00  0.260000  \n",
              " 2023-03-18 17:00:00  0.230000  \n",
              " 2023-03-18 18:00:00  0.250000  \n",
              " 2023-03-18 19:00:00  0.250000  \n",
              " \n",
              " [17564 rows x 6 columns],\n",
              " 'O3':                         NO          WD         AT         RH        WS      O3\n",
              " time                                                                          \n",
              " 2021-03-17 00:00:00   7.97  236.970000  25.740000  44.770000  0.820000   3.470\n",
              " 2021-03-17 01:00:00   7.97  219.323333  25.523333  50.273333  0.846667   3.566\n",
              " 2021-03-17 02:00:00   7.97  201.676667  25.306667  55.776667  0.873333   3.662\n",
              " 2021-03-17 03:00:00   7.97  184.030000  25.090000  61.280000  0.900000   3.758\n",
              " 2021-03-17 04:00:00  17.54  151.750000  24.715000  60.695000  0.815000   3.854\n",
              " ...                    ...         ...        ...        ...       ...     ...\n",
              " 2023-03-18 15:00:00  10.18  231.420000  32.500000  62.990000  2.590000  49.060\n",
              " 2023-03-18 16:00:00  12.90  242.130000  31.920000  66.230000  2.860000  44.690\n",
              " 2023-03-18 17:00:00  10.55  243.530000  31.170000  70.650000  2.540000  48.020\n",
              " 2023-03-18 18:00:00  10.98  244.630000  30.360000  77.600000  2.050000  43.670\n",
              " 2023-03-18 19:00:00  10.98  244.630000  30.360000  77.600000  2.050000  43.670\n",
              " \n",
              " [17564 rows x 6 columns],\n",
              " 'SO2':                         NO          WD         AT         RH        WS     SO2\n",
              " time                                                                          \n",
              " 2021-03-17 00:00:00   7.97  236.970000  25.740000  44.770000  0.820000  73.270\n",
              " 2021-03-17 01:00:00   7.97  219.323333  25.523333  50.273333  0.846667  67.162\n",
              " 2021-03-17 02:00:00   7.97  201.676667  25.306667  55.776667  0.873333  61.054\n",
              " 2021-03-17 03:00:00   7.97  184.030000  25.090000  61.280000  0.900000  54.946\n",
              " 2021-03-17 04:00:00  17.54  151.750000  24.715000  60.695000  0.815000  48.838\n",
              " ...                    ...         ...        ...        ...       ...     ...\n",
              " 2023-03-18 15:00:00  10.18  231.420000  32.500000  62.990000  2.590000  25.550\n",
              " 2023-03-18 16:00:00  12.90  242.130000  31.920000  66.230000  2.860000  25.540\n",
              " 2023-03-18 17:00:00  10.55  243.530000  31.170000  70.650000  2.540000  25.560\n",
              " 2023-03-18 18:00:00  10.98  244.630000  30.360000  77.600000  2.050000  25.550\n",
              " 2023-03-18 19:00:00  10.98  244.630000  30.360000  77.600000  2.050000  25.550\n",
              " \n",
              " [17564 rows x 6 columns]}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "airQualTypesDataDict(aq_kurla)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# return training & validation data\n",
        "def splitTrainValData(data_df, label, n_in, is_predict):\n",
        "    # pred_size\n",
        "    pred_size = 48\n",
        "    \n",
        "    # reframed dataset\n",
        "    data_df = data_df.astype(float)\n",
        "    \n",
        "    # extract the label column firstly\n",
        "    features_df = data_df.drop(columns=[label])\n",
        "    label_col = data_df[[label]]\n",
        "    \n",
        "    reframed = series_to_supervised(features_df, n_in)\n",
        "    # concat the label column\n",
        "    reframed = reframed.merge(label_col, on='time', how='left')\n",
        "    \n",
        "    # drop the NaN the last 48 hours before\n",
        "    reframed_test = reframed[-pred_size:]\n",
        "    reframed_train = reframed[:-pred_size]\n",
        "    reframed_train = reframed_train.dropna()\n",
        "    \n",
        "    reframed_all = pd.DataFrame()\n",
        "    if is_predict:\n",
        "        # reframed data including the test set for final prediction\n",
        "        reframed_all = pd.concat([reframed_train, reframed_test], ignore_index=False)\n",
        "    else:\n",
        "        # reframed data including the validation dataset\n",
        "        reframed_all = reframed_train\n",
        "    \n",
        "    # split into train and test sets\n",
        "    # index\n",
        "    train_index = reframed_all.index[:-pred_size]\n",
        "    test_index = reframed_all.index[-pred_size:]\n",
        "    \n",
        "    values = reframed_all.values\n",
        "    # scaled features\n",
        "    features_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_features = features_scaler.fit_transform(values[:,:-1])\n",
        "    \n",
        "    # scaled labels\n",
        "    labels_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_label = labels_scaler.fit_transform(values[:,-1].reshape(-1,1))\n",
        "    values = np.column_stack((scaled_features, scaled_label))\n",
        "\n",
        "    # split the train & test\n",
        "    train = values[:-pred_size, :]\n",
        "    test = values[-pred_size:, :]\n",
        "    \n",
        "    # split into input and outputs\n",
        "    # features take all values except the var1\n",
        "    train_X, train_y = train[:, :-1], train[:, -1]\n",
        "    test_X, test_y = test[:, :-1], test[:, -1]\n",
        "    \n",
        "    return train_X, test_X, train_y, test_y, train_index, test_index, labels_scaler\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "# from evaluate import smape\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "def smape(actual, predicted):\n",
        "    dividend= np.abs(np.array(actual) - np.array(predicted))\n",
        "    denominator = np.array(actual) + np.array(predicted)\n",
        "    \n",
        "    return 2 * np.mean(np.divide(dividend, denominator, out=np.zeros_like(dividend), where=denominator!=0, casting='unsafe'))\n",
        "\n",
        "\n",
        "# from evaluation import smape\n",
        "\n",
        "def evaluation(real, pred):\n",
        "    mse_score = mean_squared_error(real, pred)\n",
        "    rmse_score = math.sqrt(mse_score)\n",
        "    smape_score = smape(real, pred)\n",
        "    \n",
        "    print (\"MSE: {}\".format(mse_score))\n",
        "    print (\"RMSE: {}\".format(rmse_score))\n",
        "    print (\"SMAPE: {}\".format(smape_score))\n",
        "    print('R^2 score: {:2f}'.format(r2_score(real, pred)))\n",
        "    return rmse_score, smape_score\n",
        "    \n",
        "A = np.array([2,3,4,5,6,7,8,9])\n",
        "F = np.array([1,3,5,4,6,7,10,7])\n",
        "print(smape(A, F))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "XG-Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipdb\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "airQ_types = ['PM2.5', 'PM10', 'O3', 'CO', 'SO2', 'NO2']\n",
        "\n",
        "def xgb(airQ_df, n_estimators, n_in, is_predict):\n",
        "    rmse_dict = {}\n",
        "    smape_dict = {}\n",
        "    for air_type in airQ_types[:3]:\n",
        "        # final optimal parameters\n",
        "        n_in = 1\n",
        "        n_est = 100\n",
        "        \n",
        "        if air_type == 'PM2.5':\n",
        "            n_in = 12\n",
        "            n_est = 1000\n",
        "        elif air_type == 'PM10':\n",
        "            n_in = 1\n",
        "            n_est = 200\n",
        "        elif air_type == 'O3':\n",
        "            n_in = 15\n",
        "            n_est = 100\n",
        "            \n",
        "        n_estimators = n_est\n",
        "            \n",
        "            \n",
        "        air_type_dict = airQualTypesDataDict(airQ_df)\n",
        "        X_train, X_val, y_train, y_val, train_index, val_index, scaler = \\\n",
        "            splitTrainValData(air_type_dict[air_type], air_type, n_in, is_predict)\n",
        "        \n",
        "        # Model\n",
        "        model_xgb = XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
        "                                 learning_rate=0.05, max_depth=3, \n",
        "                                 min_child_weight=1.7817, n_estimators=n_estimators,\n",
        "                                 reg_alpha=0.4640, reg_lambda=0.8571,\n",
        "                                 subsample=0.5213, silent=1,\n",
        "                                 random_state =7, nthread = -1)\n",
        "\n",
        "        # time count\n",
        "        start = time.time()\n",
        "\n",
        "        # make a prediction\n",
        "        model_xgb.fit(X_train, y_train)\n",
        "        yhat = model_xgb.predict(X_val)\n",
        "\n",
        "        # invert scaling for forecast\n",
        "#         inv_yhat = concatenate((yhat, X_val[:, 1:]), axis=1)\n",
        "        inv_yhat = scaler.inverse_transform(yhat.reshape(-1, 1))\n",
        "        inv_yhat = inv_yhat[:,0]\n",
        "\n",
        "        # invert scaling for actual\n",
        "#         y_val = y_val.reshape((len(y_val), 1))\n",
        "#         inv_y = concatenate((y_val, X_val[:, 1:]), axis=1)\n",
        "        inv_y = scaler.inverse_transform(y_val.reshape(-1, 1))\n",
        "        inv_y = inv_y[:,0]\n",
        "\n",
        "        end = time.time()\n",
        "        print('This took {} seconds.'.format(end - start))\n",
        "\n",
        "        # inversed labels dataframe\n",
        "        y_val_inversed = inv_y\n",
        "        y_val_inversed_df = pd.DataFrame(y_val_inversed, index=val_index, columns=[air_type])\n",
        "\n",
        "        pred_inversed = [x if x > 0 else 0 for x in inv_yhat]\n",
        "        pred_inversed_df = pd.DataFrame(pred_inversed, index=val_index, columns=[air_type])\n",
        "\n",
        "        # Evaluation result\n",
        "        rmse_score, smape_score = evaluation(y_val_inversed, pred_inversed)\n",
        "        rmse_dict[air_type] = rmse_score\n",
        "        smape_dict[air_type] = smape_score\n",
        "\n",
        "        # draw line chart\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        ax.plot(val_index, y_val_inversed_df[[air_type]], color='b', label='True')\n",
        "        ax.plot(val_index, pred_inversed_df[[air_type]], color='orange', label='Prediction')\n",
        "\n",
        "        ax.set_title(air_type, fontweight=\"bold\", size=16)\n",
        "        ax.legend(loc=\"upper right\")\n",
        "        myFmt = DateFormatter(\"%m %d %H\")\n",
        "        ax.xaxis.set_major_formatter(myFmt)\n",
        "\n",
        "        ## Rotate date labels automatically\n",
        "        fig.autofmt_xdate()\n",
        "        plt.show()\n",
        "        \n",
        "    return rmse_dict, smape_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "aq_kurla.rename(columns = {'Date':'time'}, inplace = True)\n",
        "aq_kurla.rename(columns = {'Ozone':'O3'}, inplace = True)\n",
        "# aq_kurla.set_index(\"time\", inplace = True)\n",
        "new_aq_kurla=aq_kurla.drop(aq_kurla[['WS','WD','RH','AT','NO']],axis=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analysis\n",
        "\n",
        "Suitable sequence hours for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================== 1 ===========================\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found array with 0 feature(s) (shape=(17516, 0)) while a minimum of 1 is required by MinMaxScaler.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[32], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m seq_hours:\n\u001b[0;32m      9\u001b[0m     \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m====================== \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m ===========================\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i))\n\u001b[1;32m---> 10\u001b[0m     rmse_dict, smape_dict \u001b[39m=\u001b[39m xgb(new_aq_kurla, \u001b[39m1000\u001b[39;49m, i, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     12\u001b[0m     \u001b[39m# O3\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     o_3[\u001b[39m'\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(rmse_dict[\u001b[39m'\u001b[39m\u001b[39mO3\u001b[39m\u001b[39m'\u001b[39m])\n",
            "Cell \u001b[1;32mIn[26], line 29\u001b[0m, in \u001b[0;36mxgb\u001b[1;34m(airQ_df, n_estimators, n_in, is_predict)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m#         n_estimators = n_est\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         air_type_dict \u001b[39m=\u001b[39m airQualTypesDataDict(airQ_df)\n\u001b[0;32m     28\u001b[0m         X_train, X_val, y_train, y_val, train_index, val_index, scaler \u001b[39m=\u001b[39m \\\n\u001b[1;32m---> 29\u001b[0m             splitTrainValData(air_type_dict[air_type], air_type, n_in, is_predict)\n\u001b[0;32m     31\u001b[0m         \u001b[39m# Model\u001b[39;00m\n\u001b[0;32m     32\u001b[0m         model_xgb \u001b[39m=\u001b[39m XGBRegressor(colsample_bytree\u001b[39m=\u001b[39m\u001b[39m0.4603\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0.0468\u001b[39m, \n\u001b[0;32m     33\u001b[0m                                  learning_rate\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, \n\u001b[0;32m     34\u001b[0m                                  min_child_weight\u001b[39m=\u001b[39m\u001b[39m1.7817\u001b[39m, n_estimators\u001b[39m=\u001b[39mn_estimators,\n\u001b[0;32m     35\u001b[0m                                  reg_alpha\u001b[39m=\u001b[39m\u001b[39m0.4640\u001b[39m, reg_lambda\u001b[39m=\u001b[39m\u001b[39m0.8571\u001b[39m,\n\u001b[0;32m     36\u001b[0m                                  subsample\u001b[39m=\u001b[39m\u001b[39m0.5213\u001b[39m, silent\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     37\u001b[0m                                  random_state \u001b[39m=\u001b[39m\u001b[39m7\u001b[39m, nthread \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
            "Cell \u001b[1;32mIn[6], line 38\u001b[0m, in \u001b[0;36msplitTrainValData\u001b[1;34m(data_df, label, n_in, is_predict)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39m# scaled features\u001b[39;00m\n\u001b[0;32m     37\u001b[0m features_scaler \u001b[39m=\u001b[39m MinMaxScaler(feature_range\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m---> 38\u001b[0m scaled_features \u001b[39m=\u001b[39m features_scaler\u001b[39m.\u001b[39;49mfit_transform(values[:,:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[0;32m     40\u001b[0m \u001b[39m# scaled labels\u001b[39;00m\n\u001b[0;32m     41\u001b[0m labels_scaler \u001b[39m=\u001b[39m MinMaxScaler(feature_range\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:427\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y)\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:466\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMinMaxScaler does not support sparse input. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using MaxAbsScaler instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    463\u001b[0m     )\n\u001b[0;32m    465\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 466\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    467\u001b[0m     X,\n\u001b[0;32m    468\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_pass,\n\u001b[0;32m    469\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    470\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    471\u001b[0m )\n\u001b[0;32m    473\u001b[0m data_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmin(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    474\u001b[0m data_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmax(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    938\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    939\u001b[0m     \u001b[39mif\u001b[39;00m n_features \u001b[39m<\u001b[39m ensure_min_features:\n\u001b[1;32m--> 940\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    941\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m feature(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m a minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m             \u001b[39m%\u001b[39m (n_features, array\u001b[39m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m    944\u001b[0m         )\n\u001b[0;32m    946\u001b[0m \u001b[39mif\u001b[39;00m copy:\n\u001b[0;32m    947\u001b[0m     \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    948\u001b[0m         \u001b[39m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(17516, 0)) while a minimum of 1 is required by MinMaxScaler."
          ]
        }
      ],
      "source": [
        "# make a comparison of the different sequence hours for prediction\n",
        "\n",
        "o_3 = {'rmse': [], 'smape': []}\n",
        "pm25 = {'rmse': [], 'smape': []}\n",
        "pm10 = {'rmse': [], 'smape': []}\n",
        "seq_hours = [1, 3, 6, 9, 12, 15, 18, 21, 24]\n",
        "\n",
        "for i in seq_hours:\n",
        "    print (\"====================== {} ===========================\".format(i))\n",
        "    rmse_dict, smape_dict = xgb(new_aq_kurla, 1000, i, False)\n",
        "    \n",
        "    # O3\n",
        "    o_3['rmse'].append(rmse_dict['O3'])\n",
        "    o_3['smape'].append(smape_dict['O3'])\n",
        "    \n",
        "    # PM2.5\n",
        "    pm25['rmse'].append(rmse_dict['PM2.5'])\n",
        "    pm25['smape'].append(smape_dict['PM2.5'])\n",
        "    \n",
        "    # PM10\n",
        "    pm10['rmse'].append(rmse_dict['PM10'])\n",
        "    pm10['smape'].append(smape_dict['PM10'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
